本项目探索大语言模型在国产AI平台“魔搭社区（ModelScope）”中的部署与应用，重点围绕 Qwen-7B-Chat 以及 DeepSeek-LLM-7B-Chat 两个主流国产开源大模型，完成了本地化部署、API调用、GPU推理优化、模型响应测试等关键流程。 
项目通过在阿里云 PAI-DSW 环境中构建 PyTorch 推理脚本，加载模型权重，实现多模型对话交互功能。测试内容涵盖中文对话推理能力、响应延迟、显存占用和部署复杂度等多个维度，并以同一输入问题进行统一测试，便于模型间的横向对比。 
最终，本项目产出了可运行的推理脚本、部署验证截图与横向评估报告，满足开放性、完整性和可测性要求。 
如何运行：终端运行 
python 1.py #这是deepseek 
python 2.py #这是qwen 
如果不行请检查torch版本以及相关环境依赖是否正确 
